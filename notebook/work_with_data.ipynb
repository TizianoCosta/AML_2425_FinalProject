{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0wPjfA6T4FOTsLhhNpid6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook per pre-elaborazione dei dati\n",
        "\n",
        "Di seguito:\n",
        "- verranno prelevati i dati e resi disponibili su variabili;\n",
        "- saranno effettuate operazioni sui dati per avvicinarsi a distribuzioni gaussiane;\n",
        "- verranno create nuove feature create a partire da quelle presenti e sarà valutata la loro significatività"
      ],
      "metadata": {
        "id": "CIs0Jhd77joY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaricamento dei dati"
      ],
      "metadata": {
        "id": "JjGgCqx9A1VO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vBLt0MJ7fSI",
        "outputId": "87a4b45e-81f2-4ca3-ec05-59f2f84d1e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip...\n",
            "Extracted files from https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip to dataset\n",
            "Downloading https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_validation_data.zip...\n",
            "Extracted files from https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_validation_data.zip to dataset\n",
            "Downloading https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_test_data.zip...\n",
            "Extracted files from https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_test_data.zip to dataset\n",
            "Download and extraction complete.\n",
            "CSV files found: ['dataset/X_validation.csv', 'dataset/X_test.csv', 'dataset/X_train.csv', 'dataset/y_train.csv']\n"
          ]
        }
      ],
      "source": [
        "# File per scaricare i dati per fare analisi di machine learning\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "# List of URLs to your zipped files on AWS\n",
        "urls = [\n",
        "    \"https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip\",\n",
        "    \"https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_validation_data.zip\",\n",
        "    \"https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_test_data.zip\",\n",
        "]\n",
        "\n",
        "# Directory to save the extracted files\n",
        "output_dir = \"dataset\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        print(f\"Downloading {url}...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "        # Read the zip file from the response content\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "            # Extract all contents to the specified output directory\n",
        "            zip_ref.extractall(output_dir)\n",
        "            print(f\"Extracted files from {url} to {output_dir}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: The downloaded file from {url} is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "print(\"Download and extraction complete.\")\n",
        "\n",
        "# Now you can access your CSV files in the 'downloaded_data' directory\n",
        "# For example, to list the files in the directory:\n",
        "import glob\n",
        "csv_files = glob.glob(os.path.join(output_dir, \"*.csv\"))\n",
        "print(\"CSV files found:\", csv_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creazione variabile dati di training\n",
        "\n",
        "Prendo i dati di train dalla cartella e creo la variabile contenente tutti i dati e lo stato di salute delle turbine."
      ],
      "metadata": {
        "id": "ei0wmEUGA8nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_training_data(x_path, y_path):\n",
        "  \"\"\"\n",
        "  Loads X_train.csv and the second column of y_train.csv into a single pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    x_path (str): The path to the X_train.csv file.\n",
        "    y_path (str): The path to the y_train.csv file.\n",
        "\n",
        "  Returns:\n",
        "    pandas.DataFrame: A DataFrame containing the data from X_train.csv\n",
        "                      and the second column of y_train.csv.\n",
        "  \"\"\"\n",
        "  x_train = pd.read_csv(x_path)\n",
        "  y_train = pd.read_csv(y_path)\n",
        "\n",
        "  # Assuming y_train has at least 2 columns and the second column is at index 1\n",
        "  if y_train.shape[1] > 1:\n",
        "    combined_data = x_train.copy()\n",
        "    combined_data['y_target'] = y_train.iloc[:, 1]\n",
        "    return combined_data\n",
        "  else:\n",
        "    print(\"Error: y_train.csv does not have a second column.\")\n",
        "    return x_train\n",
        "\n",
        "# Example usage:\n",
        "# Assuming your files are in the 'dataset' directory as per the preceding code\n",
        "x_train_path = 'dataset/X_train.csv'\n",
        "y_train_path = 'dataset/y_train.csv'\n",
        "\n",
        "data_train = load_training_data(x_train_path, y_train_path)\n",
        "\n",
        "# You can now work with the 'training_data' DataFrame\n",
        "print(data_train.head())\n"
      ],
      "metadata": {
        "id": "VRFm7gIdR48e",
        "outputId": "51bdf519-3b08-446b-9725-b35051eca0ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  trq_measured       oat       mgt         pa       ias         np  \\\n",
            "0   0        54.100   2.00000  544.5000   212.1408  74.56250   89.18000   \n",
            "1   1        49.625  24.22231  578.4844  1625.6400  30.35596   99.55273   \n",
            "2   2        52.000   7.00000  566.1000  1912.9250  65.62500  100.14000   \n",
            "3   3        62.400   7.25000  560.1000   277.0632  54.81250   90.64000   \n",
            "4   4        62.900  23.25000  593.7000    53.6448  73.43750   99.91000   \n",
            "\n",
            "         ng  y_target  \n",
            "0   99.6400         1  \n",
            "1   91.3866         0  \n",
            "2   90.9600         1  \n",
            "3  100.2800         0  \n",
            "4   92.1700         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cambio dei nomi delle feature"
      ],
      "metadata": {
        "id": "cK37LbnxQS-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rename_dataframe_columns(df, new_column_names):\n",
        "  \"\"\"\n",
        "  Renames the columns of a pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    df: The pandas DataFrame whose columns are to be renamed.\n",
        "    new_column_names: A list of new column names. The length of this list\n",
        "                      must match the number of columns in the DataFrame.\n",
        "\n",
        "  Returns:\n",
        "    The DataFrame with renamed columns.\n",
        "  \"\"\"\n",
        "  if len(new_column_names) != len(df.columns):\n",
        "    raise ValueError(\"The number of new column names must match the number of existing columns.\")\n",
        "  df.columns = new_column_names\n",
        "  return df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have a list of new names for your columns\n",
        "new_names_for_train_data = ['idx', 'torque_meas', 'outside_air_temp', 'mean_gas_temp', 'power_avail', 'indicated_air_speed', 'net_power', 'compressor_speed', 'health_state'] # Replace with your desired names\n",
        "\n",
        "# Rename the columns of data_train\n",
        "# Ensure the number of names in new_names_for_train_data matches the number of columns in data_train\n",
        "print(f\"Number of columns in data_train: {len(data_train.columns)}\")\n",
        "print(f\"Number of new names provided: {len(new_names_for_train_data)}\")\n",
        "\n",
        "data_train = rename_dataframe_columns(data_train, new_names_for_train_data)\n",
        "print(\"\\nDataFrame after renaming columns:\")\n",
        "print(data_train.head())"
      ],
      "metadata": {
        "id": "g_6S5u7YQWaO",
        "outputId": "f66e7ffe-67d9-4702-e837-3748ae21ef2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns in data_train: 9\n",
            "Number of new names provided: 9\n",
            "\n",
            "DataFrame after renaming columns:\n",
            "   idx  torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "0    0       54.100           2.00000       544.5000     212.1408   \n",
            "1    1       49.625          24.22231       578.4844    1625.6400   \n",
            "2    2       52.000           7.00000       566.1000    1912.9250   \n",
            "3    3       62.400           7.25000       560.1000     277.0632   \n",
            "4    4       62.900          23.25000       593.7000      53.6448   \n",
            "\n",
            "   indicated_air_speed  net_power  compressor_speed  health_state  \n",
            "0             74.56250   89.18000           99.6400             1  \n",
            "1             30.35596   99.55273           91.3866             0  \n",
            "2             65.62500  100.14000           90.9600             1  \n",
            "3             54.81250   90.64000          100.2800             0  \n",
            "4             73.43750   99.91000           92.1700             0  \n"
          ]
        }
      ]
    }
  ]
}