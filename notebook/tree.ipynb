{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDM-HtmPZJpM"
      },
      "source": [
        "# Tree\n",
        "Questo notebook serve per racchiudere quanto di utile per lo sviluppo di codice per valutare la scelta di alberi decisionali per il dataset scelto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMd2ihQ1ZpS6"
      },
      "source": [
        "## Scaricamento dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vBLt0MJ7fSI",
        "outputId": "cd23a251-409d-4380-9619-114a7e138abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip...\n",
            "Extracted files from https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip to dataset\n",
            "Download and extraction complete.\n",
            "CSV files found: ['dataset/X_train.csv', 'dataset/y_train.csv']\n"
          ]
        }
      ],
      "source": [
        "# File per scaricare i dati per fare analisi di machine learning\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "# List of URLs to your zipped files on AWS\n",
        "urls = [\n",
        "    \"https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip\"]\n",
        "\n",
        "# Directory to save the extracted files\n",
        "output_dir = \"dataset\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        print(f\"Downloading {url}...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "        # Read the zip file from the response content\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "            # Extract all contents to the specified output directory\n",
        "            zip_ref.extractall(output_dir)\n",
        "            print(f\"Extracted files from {url} to {output_dir}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: The downloaded file from {url} is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "print(\"Download and extraction complete.\")\n",
        "\n",
        "# Now you can access your CSV files in the 'downloaded_data' directory\n",
        "# For example, to list the files in the directory:\n",
        "import glob\n",
        "csv_files = glob.glob(os.path.join(output_dir, \"*.csv\"))\n",
        "print(\"CSV files found:\", csv_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er3mr_yCZyR7"
      },
      "source": [
        "## Estrazione dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRFm7gIdR48e",
        "outputId": "d637999c-f61e-4775-c50c-fb92c62fd267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id  trq_measured       oat       mgt         pa       ias         np  \\\n",
            "0   0        54.100   2.00000  544.5000   212.1408  74.56250   89.18000   \n",
            "1   1        49.625  24.22231  578.4844  1625.6400  30.35596   99.55273   \n",
            "2   2        52.000   7.00000  566.1000  1912.9250  65.62500  100.14000   \n",
            "3   3        62.400   7.25000  560.1000   277.0632  54.81250   90.64000   \n",
            "4   4        62.900  23.25000  593.7000    53.6448  73.43750   99.91000   \n",
            "\n",
            "         ng  y_target  \n",
            "0   99.6400         1  \n",
            "1   91.3866         0  \n",
            "2   90.9600         1  \n",
            "3  100.2800         0  \n",
            "4   92.1700         0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(x_path, y_path):\n",
        "  \"\"\"\n",
        "  Loads X.csv and the second column of y.csv into a single pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    x_path (str): The path to the X.csv file.\n",
        "    y_path (str): The path to the y.csv file.\n",
        "\n",
        "  Returns:\n",
        "    pandas.DataFrame: A DataFrame containing the data from X.csv\n",
        "                      and the second column of y.csv.\n",
        "  \"\"\"\n",
        "  x = pd.read_csv(x_path)\n",
        "  y = pd.read_csv(y_path)\n",
        "\n",
        "  # Assuming y has at least 2 columns and the second column is at index 1\n",
        "  if y.shape[1] > 1:\n",
        "    combined_data = x.copy()\n",
        "    combined_data['y_target'] = y.iloc[:, 1]\n",
        "    return combined_data\n",
        "  else:\n",
        "    print(\"Error: y.csv does not have a second column.\")\n",
        "    return x\n",
        "\n",
        "# Example usage:\n",
        "# Assuming your files are in the 'dataset' directory as per the preceding code\n",
        "x_path = 'dataset/X_train.csv'\n",
        "y_path = 'dataset/y_train.csv'\n",
        "\n",
        "data = load_data(x_path, y_path)\n",
        "\n",
        "# You can now work with the 'data' DataFrame\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_-Gtljcq3v4"
      },
      "source": [
        "## Creazione training-set testing-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqia2aOJX_MR",
        "outputId": "9ac8a6a8-e0a0-4d6f-afc2-5be920a93ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensione data_train: (594100, 9)\n",
            "Dimensione data_test: (148525, 9)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dimensione data_train:\", data_train.shape)\n",
        "print(\"Dimensione data_test:\", data_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lpARpCCgreg"
      },
      "source": [
        "## Cambio nome delle feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPNHbqucguH5",
        "outputId": "a7f8c786-cb28-45e0-8faa-73df7f5b56aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Renamed DataFrame (without 'id'):\n",
            "        torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "331067      74.8000            19.500       646.1000    1005.8400   \n",
            "601458      67.0332            20.152       602.4063     958.4962   \n",
            "77053       67.8000             8.000       546.7000      24.3840   \n",
            "664037      53.9000             5.500       532.1000     360.8832   \n",
            "346977      73.3000            17.750       636.3000    1025.9570   \n",
            "\n",
            "        indicated_air_speed  net_power  compressor_speed  health_state  \n",
            "331067             56.00000  100.19000          96.47000             1  \n",
            "601458             96.97656   99.65235          94.02332             0  \n",
            "77053              73.68750  100.22000          91.61000             0  \n",
            "664037             61.87500   88.91000          99.78000             0  \n",
            "346977             89.50000   99.98000          95.95000             1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        is_tuple = isinstance(X, tuple)\n",
        "        if is_tuple:\n",
        "            if not X:\n",
        "                raise ValueError(\"Input tuple is empty.\")\n",
        "            df = X[0]\n",
        "            rest = X[1:]\n",
        "        else:\n",
        "            df = X\n",
        "            rest = ()\n",
        "\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Input (or first element if tuple) must be a DataFrame.\")\n",
        "\n",
        "        # Drop 'id' column if present\n",
        "        if 'id' in df.columns:\n",
        "            df = df.drop(columns='id')\n",
        "\n",
        "        # Check column count matches\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if len(self.column_names) + 1 == df.shape[1] and 'faulty' in df.columns:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                new_cols = self.column_names + ['faulty']\n",
        "                if len(new_cols) != df.shape[1]:\n",
        "                    raise ValueError(\"Mismatch in column count with 'faulty' included.\")\n",
        "                df_renamed = df.copy()\n",
        "                df_renamed.columns = new_cols\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df_renamed = df.copy()\n",
        "            df_renamed.columns = self.column_names\n",
        "\n",
        "        return (df_renamed,) + rest if rest else df_renamed\n",
        "\n",
        "# ---------------------- Setup ----------------------\n",
        "new_names_for_train_data = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed', 'health_state'\n",
        "]\n",
        "\n",
        "# ---------------------- Pipeline ----------------------\n",
        "pipeline_with_renaming = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data))\n",
        "])\n",
        "\n",
        "# Apply pipeline\n",
        "data_train_renamed = pipeline_with_renaming.fit_transform(data_train)\n",
        "\n",
        "# ---------------------- Output ----------------------\n",
        "print(\"Renamed DataFrame (without 'id'):\")\n",
        "print(data_train_renamed.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVwb2LUAdtDE"
      },
      "source": [
        "## Standardizzazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gwq2cWHdvYY",
        "outputId": "fe4dd439-e216-4ade-cbe4-0033f57ee10f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Scaled and Split Data:\n",
            "Train shape: (594100, 8)\n",
            "Sample scaled train data:\n",
            "         torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "331067     0.731935          0.845806       1.357989     0.877700   \n",
            "601458     0.145607          0.926646       0.255597     0.793633   \n",
            "77053      0.203494         -0.580045      -1.149874    -0.865050   \n",
            "664037    -0.845839         -0.890013      -1.518232    -0.267535   \n",
            "346977     0.618698          0.628829       1.110735     0.913422   \n",
            "\n",
            "        indicated_air_speed  net_power  compressor_speed  health_state  \n",
            "331067            -0.659161   0.703895          0.261704             1  \n",
            "601458             0.498516   0.569311         -0.411386             0  \n",
            "77053             -0.159451   0.711405         -1.075299             0  \n",
            "664037            -0.493179  -2.119706          1.172296             0  \n",
            "346977             0.287287   0.651328          0.118650             1  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tizianoc/.local/lib/python3.10/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Each input must be a DataFrame.\")\n",
        "\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if 'faulty' in df.columns and len(self.column_names) + 1 == df.shape[1]:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                df.columns = self.column_names + ['faulty']\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df.columns = self.column_names\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            return tuple(self._rename_df(df) for df in X)\n",
        "        else:\n",
        "            return self._rename_df(X)\n",
        "\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        self.scaler.fit(X[self.feature_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_scaled = X.copy()\n",
        "        X_scaled[self.feature_columns] = self.scaler.transform(X[self.feature_columns])\n",
        "\n",
        "        return X_scaled\n",
        "\n",
        "# ---------------------- Example Usage ----------------------\n",
        "\n",
        "# Example column names\n",
        "new_names_for_train_data = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed', 'health_state'\n",
        "]\n",
        "\n",
        "data_test = data_train.copy()  # For simplicity\n",
        "\n",
        "# Pipeline\n",
        "pipeline_with_scaling = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data)),\n",
        "    ('scale_data', DataScaler())\n",
        "])\n",
        "\n",
        "pipeline_with_scaling.fit(data_train)\n",
        "# Apply pipeline\n",
        "scaled_data = pipeline_with_scaling.transform(data_train_renamed)\n",
        "\n",
        "# Output\n",
        "print(\"\\nScaled and Split Data:\")\n",
        "print(\"Train shape:\", scaled_data.shape)\n",
        "print(\"Sample scaled train data:\\n\", scaled_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iB37YNe03k"
      },
      "source": [
        "## Decision tree prima esecuzione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_xW18Aae4Jp",
        "outputId": "9ae737f5-774c-46e1-fbd4-a8d6ae0b3283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Decision Tree Classifier with criterion='gini'...\n",
            "Decision Tree model training complete.\n",
            "\n",
            "Decision Tree Pipeline Execution Complete.\n",
            "Trained Decision Tree Model:         torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "331067     0.731935          0.845806       1.357989     0.877700   \n",
            "601458     0.145607          0.926646       0.255597     0.793633   \n",
            "77053      0.203494         -0.580045      -1.149874    -0.865050   \n",
            "664037    -0.845839         -0.890013      -1.518232    -0.267535   \n",
            "346977     0.618698          0.628829       1.110735     0.913422   \n",
            "...             ...               ...            ...          ...   \n",
            "259178    -0.664659          1.527735      -0.408111    -0.677244   \n",
            "365838    -0.189062         -1.137987      -0.090213    -0.758428   \n",
            "131932     1.237729         -1.230977       1.668318    -0.277277   \n",
            "671155    -0.429721         -1.166401       0.023796     3.025799   \n",
            "121958     2.128529          1.372751       2.558937    -0.976001   \n",
            "\n",
            "        indicated_air_speed  net_power  compressor_speed  health_state  \n",
            "331067            -0.659161   0.703895          0.261704             1  \n",
            "601458             0.498516   0.569311         -0.411386             0  \n",
            "77053             -0.159451   0.711405         -1.075299             0  \n",
            "664037            -0.493179  -2.119706          1.172296             0  \n",
            "346977             0.287287   0.651328          0.118650             1  \n",
            "...                     ...        ...               ...           ...  \n",
            "259178            -0.314838   0.671353         -1.256867             0  \n",
            "365838            -0.000532  -1.466373          1.243823             1  \n",
            "131932             0.930024  -0.297382          1.241072             1  \n",
            "671155             0.496198   0.626999         -0.681654             1  \n",
            "121958            -2.241282   0.378480          1.260329             0  \n",
            "\n",
            "[594100 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Each input must be a DataFrame.\")\n",
        "\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if 'faulty' in df.columns and len(self.column_names) + 1 == df.shape[1]:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                df.columns = self.column_names + ['faulty']\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df.columns = self.column_names\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            return tuple(self._rename_df(df) for df in X)\n",
        "        else:\n",
        "            return self._rename_df(X)\n",
        "\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        self.scaler.fit(X[self.feature_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_scaled = X.copy()\n",
        "        X_scaled[self.feature_columns] = self.scaler.transform(X[self.feature_columns])\n",
        "\n",
        "        return X_scaled\n",
        "\n",
        "\n",
        "class DecisionTreeTrainer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        X_train = X[self.feature_columns]\n",
        "        y_train = X[self.target_column]\n",
        "\n",
        "        print(f\"Training Decision Tree Classifier with criterion='{self.model.criterion}'...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "        print(\"Decision Tree model training complete.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Qui trasformiamo X restituendo X senza modifiche,\n",
        "        # oppure potresti anche ritornare solo il modello, dipende da cosa ti serve.\n",
        "        # Per mantenere compatibilità con pipeline, ritorniamo il DataFrame non modificato.\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_feat = X[self.feature_columns]\n",
        "        return self.model.predict(X_feat)\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------- Example Usage ----------------------\n",
        "\n",
        "# Example column names\n",
        "new_names_for_train_data = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed', 'health_state'\n",
        "]\n",
        "\n",
        "# Copia del dataset originale\n",
        "data_train_copy = data_train.copy()\n",
        "\n",
        "# Pipeline\n",
        "pipeline_with_decision_tree = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data)),\n",
        "    ('scale_data', DataScaler()),\n",
        "    ('train_decision_tree', DecisionTreeTrainer())\n",
        "])\n",
        "\n",
        "# Applichiamo il fit_transform sull'intero DataFrame\n",
        "trained_output = pipeline_with_decision_tree.fit_transform(data_train_copy)\n",
        "\n",
        "# Output\n",
        "print(\"\\nDecision Tree Pipeline Execution Complete.\")\n",
        "print(\"Trained Decision Tree Model:\", trained_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2g81-7dbZuY"
      },
      "source": [
        "## K-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILYQclNobcus",
        "outputId": "9832def3-0252-4679-d370-eb40497125a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Decision Tree Classifier with criterion='gini'...\n",
            "Decision Tree model training complete.\n",
            "\n",
            "Performing 5-Fold Cross-Validation on training data...\n",
            "Cross-validation complete.\n",
            "Cross-validation scores (5 folds): [0.99659148 0.99649049 0.99693654 0.99637266 0.9965494 ]\n",
            "Mean CV score: 0.9966\n",
            "Standard deviation of CV scores: 0.0002\n",
            "\n",
            "Decision Tree Pipeline Execution Complete.\n",
            "Trained Decision Tree Model:         torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "331067     0.731935          0.845806       1.357989     0.877700   \n",
            "601458     0.145607          0.926646       0.255597     0.793633   \n",
            "77053      0.203494         -0.580045      -1.149874    -0.865050   \n",
            "664037    -0.845839         -0.890013      -1.518232    -0.267535   \n",
            "346977     0.618698          0.628829       1.110735     0.913422   \n",
            "...             ...               ...            ...          ...   \n",
            "259178    -0.664659          1.527735      -0.408111    -0.677244   \n",
            "365838    -0.189062         -1.137987      -0.090213    -0.758428   \n",
            "131932     1.237729         -1.230977       1.668318    -0.277277   \n",
            "671155    -0.429721         -1.166401       0.023796     3.025799   \n",
            "121958     2.128529          1.372751       2.558937    -0.976001   \n",
            "\n",
            "        indicated_air_speed  net_power  compressor_speed  health_state  \n",
            "331067            -0.659161   0.703895          0.261704             1  \n",
            "601458             0.498516   0.569311         -0.411386             0  \n",
            "77053             -0.159451   0.711405         -1.075299             0  \n",
            "664037            -0.493179  -2.119706          1.172296             0  \n",
            "346977             0.287287   0.651328          0.118650             1  \n",
            "...                     ...        ...               ...           ...  \n",
            "259178            -0.314838   0.671353         -1.256867             0  \n",
            "365838            -0.000532  -1.466373          1.243823             1  \n",
            "131932             0.930024  -0.297382          1.241072             1  \n",
            "671155             0.496198   0.626999         -0.681654             1  \n",
            "121958            -2.241282   0.378480          1.260329             0  \n",
            "\n",
            "[594100 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# prompt: vorrei aggiungessi alla pipeline una validazione su data_train con un 5-fold, di scoring non mettere ancora nulla, lo aggiungerei poi\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Each input must be a DataFrame.\")\n",
        "\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if 'faulty' in df.columns and len(self.column_names) + 1 == df.shape[1]:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                df.columns = self.column_names + ['faulty']\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df.columns = self.column_names\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            return tuple(self._rename_df(df) for df in X)\n",
        "        else:\n",
        "            return self._rename_df(X)\n",
        "\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        self.scaler.fit(X[self.feature_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_scaled = X.copy()\n",
        "        X_scaled[self.feature_columns] = self.scaler.transform(X[self.feature_columns])\n",
        "\n",
        "        return X_scaled\n",
        "\n",
        "\n",
        "class DecisionTreeTrainer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        X_train = X[self.feature_columns]\n",
        "        y_train = X[self.target_column]\n",
        "\n",
        "        print(f\"Training Decision Tree Classifier with criterion='{self.model.criterion}'...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "        print(\"Decision Tree model training complete.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Qui trasformiamo X restituendo X senza modifiche,\n",
        "        # oppure potresti anche ritornare solo il modello, dipende da cosa ti serve.\n",
        "        # Per mantenere compatibilità con pipeline, ritorniamo il DataFrame non modificato.\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_feat = X[self.feature_columns]\n",
        "        return self.model.predict(X_feat)\n",
        "\n",
        "class DecisionTreeCrossValidator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_splits=5, random_state=None, shuffle=True):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "        self.shuffle = shuffle\n",
        "        self.cv_scores = None\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_train = X.iloc[:, :-1]\n",
        "        y_train = X.iloc[:, -1]\n",
        "\n",
        "        kf = KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
        "\n",
        "        print(f\"\\nPerforming {self.n_splits}-Fold Cross-Validation on training data...\")\n",
        "        self.cv_scores = cross_val_score(\n",
        "            self.model,\n",
        "            X_train,\n",
        "            y_train,\n",
        "            cv=kf,\n",
        "            scoring='accuracy'  # puoi cambiare scoring se vuoi\n",
        "        )\n",
        "        print(\"Cross-validation complete.\")\n",
        "        print(f\"Cross-validation scores ({self.n_splits} folds): {self.cv_scores}\")\n",
        "        print(f\"Mean CV score: {self.cv_scores.mean():.4f}\")\n",
        "        print(f\"Standard deviation of CV scores: {self.cv_scores.std():.4f}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        # Non modifichiamo X, solo ritorniamo lo stesso DataFrame per compatibilità pipeline\n",
        "        return X\n",
        "\n",
        "    def get_cv_scores(self):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        return self.cv_scores\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------- Example Usage ----------------------\n",
        "\n",
        "# Example column names\n",
        "new_names_for_train_data = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed', 'health_state'\n",
        "]\n",
        "\n",
        "# Pipeline\n",
        "pipeline_with_cross_validation = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data)),\n",
        "    ('scale_data', DataScaler()),\n",
        "    ('train_decision_tree', DecisionTreeTrainer()),\n",
        "    ('cross_validate_decision_tree', DecisionTreeCrossValidator(n_splits=5, random_state=42))\n",
        "])\n",
        "\n",
        "# Apply pipeline\n",
        "trained_model_cross_val = pipeline_with_cross_validation.fit_transform((data_train_renamed))\n",
        "\n",
        "# Output\n",
        "print(\"\\nDecision Tree Pipeline Execution Complete.\")\n",
        "print(\"Trained Decision Tree Model:\", trained_model_cross_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUInhu7anla4"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bQmqTq2lnnFH",
        "outputId": "27698b60-6dcb-4e59-9607-69c0a4319b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Decision Tree Classifier with criterion='gini'...\n",
            "Decision Tree model training complete.\n",
            "\n",
            "Performing 5-Fold Cross-Validation on training data...\n",
            "Cross-validation complete.\n",
            "Cross-validation scores (5 folds): [0.99659148 0.99649049 0.99693654 0.99637266 0.9965494 ]\n",
            "Mean CV score: 0.9966\n",
            "Standard deviation of CV scores: 0.0002\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "PerformanceEvaluator.fit() missing 1 required positional argument: 'y'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 230\u001b[0m\n\u001b[1;32m    221\u001b[0m pipeline_with_evaluation \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m    222\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrename_features\u001b[39m\u001b[38;5;124m'\u001b[39m, FeatureRenamer(column_names\u001b[38;5;241m=\u001b[39mnew_names_for_train_data)),\n\u001b[1;32m    223\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_data\u001b[39m\u001b[38;5;124m'\u001b[39m, DataScaler()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate_performance\u001b[39m\u001b[38;5;124m'\u001b[39m, PerformanceEvaluator()) \u001b[38;5;66;03m# Add the evaluator\u001b[39;00m\n\u001b[1;32m    227\u001b[0m ])\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Apply pipeline\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m trained_model_evaluated \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_with_evaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Access the evaluation results\u001b[39;00m\n\u001b[1;32m    233\u001b[0m accuracy, precision, sensitivity, specificity, cm, fpr, tpr, roc_auc \u001b[38;5;241m=\u001b[39m trained_model_evaluated[:\u001b[38;5;241m8\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:730\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    724\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    725\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    726\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    727\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    728\u001b[0m )\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    735\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    736\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "\u001b[0;31mTypeError\u001b[0m: PerformanceEvaluator.fit() missing 1 required positional argument: 'y'"
          ]
        }
      ],
      "source": [
        "# prompt: dalla pipeline di cui sopra vorrei che facessi calcoli su indici di performance: accuracy, precision, sensitivity, specificity, che facessi una confusion matrix, una ROC e calcolassi Area Under the Curve AUC\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Each input must be a DataFrame.\")\n",
        "\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if 'faulty' in df.columns and len(self.column_names) + 1 == df.shape[1]:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                df.columns = self.column_names + ['faulty']\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df.columns = self.column_names\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            return tuple(self._rename_df(df) for df in X)\n",
        "        else:\n",
        "            return self._rename_df(X)\n",
        "\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        self.scaler.fit(X[self.feature_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_scaled = X.copy()\n",
        "        X_scaled[self.feature_columns] = self.scaler.transform(X[self.feature_columns])\n",
        "\n",
        "        return X_scaled\n",
        "\n",
        "\n",
        "class DecisionTreeTrainer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        X_train = X[self.feature_columns]\n",
        "        y_train = X[self.target_column]\n",
        "\n",
        "        print(f\"Training Decision Tree Classifier with criterion='{self.model.criterion}'...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "        print(\"Decision Tree model training complete.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Qui trasformiamo X restituendo X senza modifiche,\n",
        "        # oppure potresti anche ritornare solo il modello, dipende da cosa ti serve.\n",
        "        # Per mantenere compatibilità con pipeline, ritorniamo il DataFrame non modificato.\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_feat = X[self.feature_columns]\n",
        "        return self.model.predict(X_feat)\n",
        "\n",
        "class DecisionTreeCrossValidator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_splits=5, random_state=None, shuffle=True):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "        self.shuffle = shuffle\n",
        "        self.cv_scores = None\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_train = X.iloc[:, :-1]\n",
        "        y_train = X.iloc[:, -1]\n",
        "\n",
        "        kf = KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
        "\n",
        "        print(f\"\\nPerforming {self.n_splits}-Fold Cross-Validation on training data...\")\n",
        "        self.cv_scores = cross_val_score(\n",
        "            self.model,\n",
        "            X_train,\n",
        "            y_train,\n",
        "            cv=kf,\n",
        "            scoring='accuracy'  # puoi cambiare scoring se vuoi\n",
        "        )\n",
        "        print(\"Cross-validation complete.\")\n",
        "        print(f\"Cross-validation scores ({self.n_splits} folds): {self.cv_scores}\")\n",
        "        print(f\"Mean CV score: {self.cv_scores.mean():.4f}\")\n",
        "        print(f\"Standard deviation of CV scores: {self.cv_scores.std():.4f}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        # Non modifichiamo X, solo ritorniamo lo stesso DataFrame per compatibilità pipeline\n",
        "        return X\n",
        "\n",
        "    def get_cv_scores(self):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        return self.cv_scores\n",
        "\n",
        "\n",
        "class PerformanceEvaluator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Valuta le performance di un modello classificatore su un set di test.\n",
        "    Salva le metriche come attributi. Funziona indipendentemente dal formato di X.\n",
        "    \"\"\"\n",
        "    def __init__(self, trained_model=None):\n",
        "        self.trained_model = trained_model\n",
        "        self.accuracy = None\n",
        "        self.precision = None\n",
        "        self.sensitivity = None\n",
        "        self.specificity = None\n",
        "        self.confusion_matrix_ = None\n",
        "        self.fpr = None\n",
        "        self.tpr = None\n",
        "        self.roc_auc = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.trained_model is None:\n",
        "            raise ValueError(\"Il modello allenato (`trained_model`) deve essere fornito.\")\n",
        "\n",
        "        print(\"\\nEvaluating model performance on the test set...\")\n",
        "\n",
        "        # Predict labels\n",
        "        y_pred = self.trained_model.predict(X)\n",
        "\n",
        "        # Compute metrics\n",
        "        self.accuracy = accuracy_score(y, y_pred)\n",
        "        self.precision = precision_score(y, y_pred, zero_division=0)\n",
        "        self.sensitivity = recall_score(y, y_pred, zero_division=0)\n",
        "\n",
        "        # Confusion matrix and specificity\n",
        "        cm = confusion_matrix(y, y_pred)\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            self.specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        else:\n",
        "            self.specificity = None\n",
        "        self.confusion_matrix_ = cm\n",
        "\n",
        "        if hasattr(self.trained_model, \"predict_proba\"):\n",
        "            y_prob = self.trained_model.predict_proba(X)[:, 1]\n",
        "            self.fpr, self.tpr, _ = roc_curve(y, y_prob)\n",
        "            self.roc_auc = auc(self.fpr, self.tpr)\n",
        "        else:\n",
        "            self.fpr = self.tpr = self.roc_auc = None\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Non altera i dati, solo per compatibilità con pipeline\n",
        "        return X\n",
        "\n",
        "    def get_results(self):\n",
        "        return {\n",
        "            \"accuracy\": self.accuracy,\n",
        "            \"precision\": self.precision,\n",
        "            \"sensitivity\": self.sensitivity,\n",
        "            \"specificity\": self.specificity,\n",
        "            \"confusion_matrix\": self.confusion_matrix_,\n",
        "            \"fpr\": self.fpr,\n",
        "            \"tpr\": self.tpr,\n",
        "            \"roc_auc\": self.roc_auc\n",
        "        }\n",
        "\n",
        "# Extend the existing pipeline to include the PerformanceEvaluator\n",
        "pipeline_with_evaluation = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data)),\n",
        "    ('scale_data', DataScaler()),\n",
        "    ('train_decision_tree', DecisionTreeTrainer()),\n",
        "    ('cross_validate_decision_tree', DecisionTreeCrossValidator(n_splits=5, random_state=42)),\n",
        "    ('evaluate_performance', PerformanceEvaluator()) # Add the evaluator\n",
        "])\n",
        "\n",
        "# Apply pipeline\n",
        "trained_model_evaluated = pipeline_with_evaluation.fit_transform((data_train))\n",
        "\n",
        "# Access the evaluation results\n",
        "accuracy, precision, sensitivity, specificity, cm, fpr, tpr, roc_auc = trained_model_evaluated[:8]\n",
        "# You can also access other outputs from previous steps if needed:\n",
        "# cv_scores, trained_dt_model, scaled_data_train, scaled_data_test = trained_model_evaluated[8:]\n",
        "\n",
        "\n",
        "print(\"\\nPerformance Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "if roc_auc is not None:\n",
        "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "    # Plot ROC Curve\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nROC curve and AUC were not plotted as predict_proba was not available.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPcFTLqUj7MyOaDI2emR3zL",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
