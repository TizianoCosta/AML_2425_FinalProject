{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDM-HtmPZJpM"
      },
      "source": [
        "# Tree\n",
        "Questo notebook serve per racchiudere quanto di utile per lo sviluppo di codice per valutare la scelta di alberi decisionali per il dataset scelto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMd2ihQ1ZpS6"
      },
      "source": [
        "## Scaricamento dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vBLt0MJ7fSI",
        "outputId": "cd23a251-409d-4380-9619-114a7e138abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip...\n",
            "Extracted files from https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip to dataset\n",
            "Download and extraction complete.\n",
            "CSV files found: ['dataset/X_train.csv', 'dataset/y_train.csv']\n"
          ]
        }
      ],
      "source": [
        "# File per scaricare i dati per fare analisi di machine learning\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "# List of URLs to your zipped files on AWS\n",
        "urls = [\n",
        "    \"https://phm-datasets.s3.amazonaws.com/Data_Challenge_PHM2024_training_data.zip\"]\n",
        "\n",
        "# Directory to save the extracted files\n",
        "output_dir = \"dataset\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        print(f\"Downloading {url}...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "        # Read the zip file from the response content\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "            # Extract all contents to the specified output directory\n",
        "            zip_ref.extractall(output_dir)\n",
        "            print(f\"Extracted files from {url} to {output_dir}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: The downloaded file from {url} is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "print(\"Download and extraction complete.\")\n",
        "\n",
        "# Now you can access your CSV files in the 'downloaded_data' directory\n",
        "# For example, to list the files in the directory:\n",
        "import glob\n",
        "csv_files = glob.glob(os.path.join(output_dir, \"*.csv\"))\n",
        "print(\"CSV files found:\", csv_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er3mr_yCZyR7"
      },
      "source": [
        "## Estrazione dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRFm7gIdR48e",
        "outputId": "d637999c-f61e-4775-c50c-fb92c62fd267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id  trq_measured       oat       mgt         pa       ias         np  \\\n",
            "0   0        54.100   2.00000  544.5000   212.1408  74.56250   89.18000   \n",
            "1   1        49.625  24.22231  578.4844  1625.6400  30.35596   99.55273   \n",
            "2   2        52.000   7.00000  566.1000  1912.9250  65.62500  100.14000   \n",
            "3   3        62.400   7.25000  560.1000   277.0632  54.81250   90.64000   \n",
            "4   4        62.900  23.25000  593.7000    53.6448  73.43750   99.91000   \n",
            "\n",
            "         ng  y_target  \n",
            "0   99.6400         1  \n",
            "1   91.3866         0  \n",
            "2   90.9600         1  \n",
            "3  100.2800         0  \n",
            "4   92.1700         0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(x_path, y_path):\n",
        "  \"\"\"\n",
        "  Loads X.csv and the second column of y.csv into a single pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    x_path (str): The path to the X.csv file.\n",
        "    y_path (str): The path to the y.csv file.\n",
        "\n",
        "  Returns:\n",
        "    pandas.DataFrame: A DataFrame containing the data from X.csv\n",
        "                      and the second column of y.csv.\n",
        "  \"\"\"\n",
        "  x = pd.read_csv(x_path)\n",
        "  y = pd.read_csv(y_path)\n",
        "\n",
        "  # Assuming y has at least 2 columns and the second column is at index 1\n",
        "  if y.shape[1] > 1:\n",
        "    combined_data = x.copy()\n",
        "    combined_data['y_target'] = y.iloc[:, 1]\n",
        "    return combined_data\n",
        "  else:\n",
        "    print(\"Error: y.csv does not have a second column.\")\n",
        "    return x\n",
        "\n",
        "# Example usage:\n",
        "# Assuming your files are in the 'dataset' directory as per the preceding code\n",
        "x_path = 'dataset/X_train.csv'\n",
        "y_path = 'dataset/y_train.csv'\n",
        "\n",
        "data = load_data(x_path, y_path)\n",
        "\n",
        "# You can now work with the 'data' DataFrame\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_-Gtljcq3v4"
      },
      "source": [
        "## Creazione training-set testing-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqia2aOJX_MR",
        "outputId": "9ac8a6a8-e0a0-4d6f-afc2-5be920a93ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensione data_train: (594100, 9)\n",
            "Dimensione data_test: (148525, 9)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dimensione data_train:\", data_train.shape)\n",
        "print(\"Dimensione data_test:\", data_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lpARpCCgreg"
      },
      "source": [
        "## Cambio nome delle feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPNHbqucguH5",
        "outputId": "a7f8c786-cb28-45e0-8faa-73df7f5b56aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed DataFrame:\n",
            "        torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "331067      74.8000            19.500       646.1000    1005.8400   \n",
            "601458      67.0332            20.152       602.4063     958.4962   \n",
            "77053       67.8000             8.000       546.7000      24.3840   \n",
            "664037      53.9000             5.500       532.1000     360.8832   \n",
            "346977      73.3000            17.750       636.3000    1025.9570   \n",
            "\n",
            "        indicated_air_speed  net_power  compressor_speed  \n",
            "331067             56.00000  100.19000          96.47000  \n",
            "601458             96.97656   99.65235          94.02332  \n",
            "77053              73.68750  100.22000          91.61000  \n",
            "664037             61.87500   88.91000          99.78000  \n",
            "346977             89.50000   99.98000          95.95000  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tizianoc/.local/lib/python3.10/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._is_fitted = True  # Mark as fitted\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "        if df.shape[1] != len(self.column_names):\n",
        "            raise ValueError(f\"Expected {len(self.column_names)} columns, got {df.shape[1]}\")\n",
        "        df.columns = self.column_names\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, '_is_fitted')  # Check if fit was called\n",
        "        return self._rename_df(X)\n",
        "\n",
        "# ---------------------- Example Usage ----------------------\n",
        "\n",
        "# Example column names\n",
        "feature_names = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed'\n",
        "]\n",
        "\n",
        "X_train = data_train.iloc[:, :-1]  # tutte le colonne tranne l'ultima → feature\n",
        "y_train = data_train.iloc[:, -1]   # solo l'ultima colonna → target\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('rename', FeatureRenamer(column_names=feature_names)),\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "X_transformed = pipeline.transform(X_train)\n",
        "\n",
        "print(\"Transformed DataFrame:\")\n",
        "print(X_transformed.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVwb2LUAdtDE"
      },
      "source": [
        "## Standardizzazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gwq2cWHdvYY",
        "outputId": "fe4dd439-e216-4ade-cbe4-0033f57ee10f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._is_fitted = True  # Mark as fitted\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "        if df.shape[1] != len(self.column_names):\n",
        "            raise ValueError(f\"Expected {len(self.column_names)} columns, got {df.shape[1]}\")\n",
        "        df.columns = self.column_names\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, '_is_fitted')  # Check if fit was called\n",
        "        return self._rename_df(X)\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns_ = X.columns  # trailing underscore indicates fitted attribute\n",
        "        self.scaler.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self.scaler, 'mean_')  # standard attribute for StandardScaler\n",
        "        X_scaled = pd.DataFrame(self.scaler.transform(X), columns=self.columns_, index=X.index)\n",
        "        return X_scaled\n",
        "\n",
        "# ---------------------- Example Usage ----------------------\n",
        "\n",
        "# Example column names\n",
        "feature_names = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed'\n",
        "]\n",
        "\n",
        "X_train = data_train.iloc[:, :-1]  # tutte le colonne tranne l'ultima → feature\n",
        "y_train = data_train.iloc[:, -1]   # solo l'ultima colonna → target\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('rename', FeatureRenamer(column_names=feature_names)),\n",
        "    ('scale', DataScaler()),\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "X_transformed = pipeline.transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iB37YNe03k"
      },
      "source": [
        "## Decision tree prima esecuzione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_xW18Aae4Jp",
        "outputId": "9ae737f5-774c-46e1-fbd4-a8d6ae0b3283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️ Pipeline fitted correttamente.\n",
            "Predizioni: [1 0 0 ... 1 1 0]\n",
            "Feature names: ['torque_meas', 'outside_air_temp', 'mean_gas_temp', 'power_avail', 'indicated_air_speed', 'net_power', 'compressor_speed']\n",
            "Predizioni, numero di elementi: 594100\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._is_fitted = True  # Mark as fitted\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "        if df.shape[1] != len(self.column_names):\n",
        "            raise ValueError(f\"Expected {len(self.column_names)} columns, got {df.shape[1]}\")\n",
        "        df.columns = self.column_names\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self, '_is_fitted')  # Check if fit was called\n",
        "        return self._rename_df(X)\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns_ = X.columns  # trailing underscore indicates fitted attribute\n",
        "        self.scaler.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self.scaler, 'mean_')  # standard attribute for StandardScaler\n",
        "        X_scaled = pd.DataFrame(self.scaler.transform(X), columns=self.columns_, index=X.index)\n",
        "        return X_scaled\n",
        "\n",
        "class DecisionTreeTrainer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "        self.is_fitted_ = True   # <-- indicatore di fit\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        check_is_fitted(self, 'is_fitted_')  # controlla se fit è stato fatto\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# ---------------------- Esecuzione Pipeline ----------------------\n",
        "\n",
        "feature_names = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed'\n",
        "]\n",
        "\n",
        "X_train = data_train.iloc[:, :-1]  # tutte le colonne tranne l'ultima → feature\n",
        "y_train = data_train.iloc[:, -1]   # solo l'ultima colonna → target\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('rename', FeatureRenamer(column_names=feature_names)),\n",
        "    ('scale', DataScaler()),\n",
        "    ('model', DecisionTreeTrainer())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "X_transformed = pipeline.transform(X_train)\n",
        "y_pred = pipeline.named_steps['model'].predict(X_transformed)\n",
        "\n",
        "check_is_fitted(pipeline.named_steps['model'])\n",
        "\n",
        "print(\"✔️ Pipeline fitted correttamente.\")\n",
        "print(\"Predizioni:\", y_pred)\n",
        "print(\"Feature names:\", pipeline.named_steps['rename'].column_names)\n",
        "print(\"Predizioni, numero di elementi:\", len(y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2g81-7dbZuY"
      },
      "source": [
        "## K-fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILYQclNobcus",
        "outputId": "9832def3-0252-4679-d370-eb40497125a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Decision Tree Classifier with criterion='gini'...\n",
            "Decision Tree model training complete.\n",
            "\n",
            "Performing 5-Fold Cross-Validation on training data...\n",
            "Cross-validation complete.\n",
            "Cross-validation scores (5 folds): [0.99586397 0.99588101 0.99645925 0.99556749 0.9958109 ]\n",
            "Mean CV score: 0.9959\n",
            "Standard deviation of CV scores: 0.0003\n",
            "\n",
            "Decision Tree Pipeline Execution Complete.\n",
            "Trained Decision Tree Model:         torque_meas  outside_air_temp  mean_gas_temp  power_avail  \\\n",
            "331067     0.731935          0.845806       1.357989     0.877700   \n",
            "601458     0.145607          0.926646       0.255597     0.793633   \n",
            "77053      0.203494         -0.580045      -1.149874    -0.865050   \n",
            "664037    -0.845839         -0.890013      -1.518232    -0.267535   \n",
            "346977     0.618698          0.628829       1.110735     0.913422   \n",
            "...             ...               ...            ...          ...   \n",
            "259178    -0.664659          1.527735      -0.408111    -0.677244   \n",
            "365838    -0.189062         -1.137987      -0.090213    -0.758428   \n",
            "131932     1.237729         -1.230977       1.668318    -0.277277   \n",
            "671155    -0.429721         -1.166401       0.023796     3.025799   \n",
            "121958     2.128529          1.372751       2.558937    -0.976001   \n",
            "\n",
            "        indicated_air_speed  net_power  compressor_speed  health_state  \n",
            "331067            -0.659161   0.703895          0.261704             1  \n",
            "601458             0.498516   0.569311         -0.411386             0  \n",
            "77053             -0.159451   0.711405         -1.075299             0  \n",
            "664037            -0.493179  -2.119706          1.172296             0  \n",
            "346977             0.287287   0.651328          0.118650             1  \n",
            "...                     ...        ...               ...           ...  \n",
            "259178            -0.314838   0.671353         -1.256867             0  \n",
            "365838            -0.000532  -1.466373          1.243823             1  \n",
            "131932             0.930024  -0.297382          1.241072             1  \n",
            "671155             0.496198   0.626999         -0.681654             1  \n",
            "121958            -2.241282   0.378480          1.260329             0  \n",
            "\n",
            "[594100 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Each input must be a DataFrame.\")\n",
        "\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if 'faulty' in df.columns and len(self.column_names) + 1 == df.shape[1]:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                df.columns = self.column_names + ['faulty']\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df.columns = self.column_names\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            return tuple(self._rename_df(df) for df in X)\n",
        "        else:\n",
        "            return self._rename_df(X)\n",
        "\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        self.scaler.fit(X[self.feature_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_scaled = X.copy()\n",
        "        X_scaled[self.feature_columns] = self.scaler.transform(X[self.feature_columns])\n",
        "\n",
        "        return X_scaled\n",
        "\n",
        "\n",
        "class DecisionTreeTrainer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        X_train = X[self.feature_columns]\n",
        "        y_train = X[self.target_column]\n",
        "\n",
        "        print(f\"Training Decision Tree Classifier with criterion='{self.model.criterion}'...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "        print(\"Decision Tree model training complete.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Qui trasformiamo X restituendo X senza modifiche,\n",
        "        # oppure potresti anche ritornare solo il modello, dipende da cosa ti serve.\n",
        "        # Per mantenere compatibilità con pipeline, ritorniamo il DataFrame non modificato.\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_feat = X[self.feature_columns]\n",
        "        return self.model.predict(X_feat)\n",
        "\n",
        "class DecisionTreeCrossValidator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_splits=5, random_state=None, shuffle=True):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "        self.shuffle = shuffle\n",
        "        self.cv_scores = None\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_train = X.iloc[:, :-1]\n",
        "        y_train = X.iloc[:, -1]\n",
        "\n",
        "        kf = KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
        "\n",
        "        print(f\"\\nPerforming {self.n_splits}-Fold Cross-Validation on training data...\")\n",
        "        self.cv_scores = cross_val_score(\n",
        "            self.model,\n",
        "            X_train,\n",
        "            y_train,\n",
        "            cv=kf,\n",
        "            scoring='precision'  # puoi cambiare scoring se vuoi\n",
        "        )\n",
        "        print(\"Cross-validation complete.\")\n",
        "        print(f\"Cross-validation scores ({self.n_splits} folds): {self.cv_scores}\")\n",
        "        print(f\"Mean CV score: {self.cv_scores.mean():.4f}\")\n",
        "        print(f\"Standard deviation of CV scores: {self.cv_scores.std():.4f}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        # Non modifichiamo X, solo ritorniamo lo stesso DataFrame per compatibilità pipeline\n",
        "        return X\n",
        "\n",
        "    def get_cv_scores(self):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        return self.cv_scores\n",
        "\n",
        "\n",
        "# ---------------------- Example Usage ----------------------\n",
        "\n",
        "# Example column names\n",
        "new_names_for_train_data = [\n",
        "    'torque_meas', 'outside_air_temp', 'mean_gas_temp',\n",
        "    'power_avail', 'indicated_air_speed', 'net_power',\n",
        "    'compressor_speed', 'health_state'\n",
        "]\n",
        "\n",
        "# Pipeline\n",
        "pipeline_with_cross_validation = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data)),\n",
        "    ('scale_data', DataScaler()),\n",
        "    ('train_decision_tree', DecisionTreeTrainer()),\n",
        "    ('cross_validate_decision_tree', DecisionTreeCrossValidator(n_splits=5, random_state=42))\n",
        "])\n",
        "\n",
        "# Apply pipeline\n",
        "trained_model_cross_val = pipeline_with_cross_validation.fit_transform(data_train)\n",
        "\n",
        "# Output\n",
        "print(\"\\nDecision Tree Pipeline Execution Complete.\")\n",
        "print(\"Trained Decision Tree Model:\", trained_model_cross_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUInhu7anla4"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bQmqTq2lnnFH",
        "outputId": "27698b60-6dcb-4e59-9607-69c0a4319b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Decision Tree Classifier with criterion='gini'...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 261\u001b[0m\n\u001b[1;32m    259\u001b[0m train_step \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_decision_tree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    260\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m \u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled_only_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# 6. Estrai il modello addestrato (assumo che l'attributo si chiami 'model')\u001b[39;00m\n\u001b[1;32m    264\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m train_step\u001b[38;5;241m.\u001b[39mmodel\n",
            "Cell \u001b[0;32mIn[23], line 89\u001b[0m, in \u001b[0;36mDecisionTreeTrainer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m y_train \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Decision Tree Classifier with criterion=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcriterion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree model training complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:1024\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:294\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[0;32m--> 294\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:222\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    214\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m ]:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------- Custom Transformers ----------------------\n",
        "\n",
        "class FeatureRenamer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column_names):\n",
        "        if not isinstance(column_names, list):\n",
        "            raise TypeError(\"column_names must be a list.\")\n",
        "        self.column_names = column_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _rename_df(self, df):\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(\"Each input must be a DataFrame.\")\n",
        "\n",
        "        df = df.drop(columns='id', errors='ignore')\n",
        "\n",
        "        if len(self.column_names) != df.shape[1]:\n",
        "            if 'faulty' in df.columns and len(self.column_names) + 1 == df.shape[1]:\n",
        "                print(\"Detected 'faulty' column, adjusting rename.\")\n",
        "                df.columns = self.column_names + ['faulty']\n",
        "            else:\n",
        "                raise ValueError(\"Column count mismatch after dropping 'id'.\")\n",
        "        else:\n",
        "            df.columns = self.column_names\n",
        "\n",
        "        return df\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, tuple):\n",
        "            return tuple(self._rename_df(df) for df in X)\n",
        "        else:\n",
        "            return self._rename_df(X)\n",
        "\n",
        "\n",
        "class DataScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        self.scaler.fit(X[self.feature_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_scaled = X.copy()\n",
        "        X_scaled[self.feature_columns] = self.scaler.transform(X[self.feature_columns])\n",
        "\n",
        "        return X_scaled\n",
        "\n",
        "\n",
        "class DecisionTreeTrainer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        self.target_column = X.columns[-1]\n",
        "        self.feature_columns = X.columns[:-1]\n",
        "\n",
        "        X_train = X[self.feature_columns]\n",
        "        y_train = X[self.target_column]\n",
        "\n",
        "        print(f\"Training Decision Tree Classifier with criterion='{self.model.criterion}'...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "        print(\"Decision Tree model training complete.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Qui trasformiamo X restituendo X senza modifiche,\n",
        "        # oppure potresti anche ritornare solo il modello, dipende da cosa ti serve.\n",
        "        # Per mantenere compatibilità con pipeline, ritorniamo il DataFrame non modificato.\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "\n",
        "        X_feat = X[self.feature_columns]\n",
        "        return self.model.predict(X_feat)\n",
        "\n",
        "class DecisionTreeCrossValidator(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_splits=5, random_state=None, shuffle=True):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "        self.shuffle = shuffle\n",
        "        self.cv_scores = None\n",
        "        self.model = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            raise TypeError(\"Input X must be a pandas DataFrame.\")\n",
        "    \n",
        "        # Controllo y: deve essere array-like o pandas Series\n",
        "        if not (isinstance(y, (pd.Series, np.ndarray))):\n",
        "            raise TypeError(\"Input y must be a pandas Series or numpy array.\")\n",
        "\n",
        "        kf = KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
        "\n",
        "        print(f\"\\nPerforming {self.n_splits}-Fold Cross-Validation on training data...\")\n",
        "        self.cv_scores = cross_val_score(\n",
        "            self.model,\n",
        "            X,\n",
        "            y,\n",
        "            cv=kf,\n",
        "            scoring='accuracy'  # puoi cambiare scoring se vuoi\n",
        "        )\n",
        "        print(\"Cross-validation complete.\")\n",
        "        print(f\"Cross-validation scores ({self.n_splits} folds): {self.cv_scores}\")\n",
        "        print(f\"Mean CV score: {self.cv_scores.mean():.4f}\")\n",
        "        print(f\"Standard deviation of CV scores: {self.cv_scores.std():.4f}\")\n",
        "\n",
        "        # Ora allena il modello completo sui dati interi (fit finale)\n",
        "        print(\"Training final model on the entire training set...\")\n",
        "        self.model.fit(X, y)\n",
        "        print(\"Final model training complete.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        # Non modifichiamo X, solo ritorniamo lo stesso DataFrame per compatibilità pipeline\n",
        "        return X\n",
        "\n",
        "    def get_cv_scores(self):\n",
        "        if self.cv_scores is None:\n",
        "            raise RuntimeError(\"Cross-validation has not been performed yet. Call fit() first.\")\n",
        "        return self.cv_scores\n",
        "\n",
        "\n",
        "class PerformanceEvaluator(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Valuta le performance di un modello classificatore su un set di test.\n",
        "    Salva le metriche come attributi. Funziona indipendentemente dal formato di X.\n",
        "    \"\"\"\n",
        "    def __init__(self, trained_model=None):\n",
        "        self.trained_model = trained_model\n",
        "        self.accuracy = None\n",
        "        self.precision = None\n",
        "        self.sensitivity = None\n",
        "        self.specificity = None\n",
        "        self.confusion_matrix_ = None\n",
        "        self.fpr = None\n",
        "        self.tpr = None\n",
        "        self.roc_auc = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.trained_model is None:\n",
        "            raise ValueError(\"Il modello allenato (`trained_model`) deve essere fornito.\")\n",
        "\n",
        "        print(\"\\nEvaluating model performance on the test set...\")\n",
        "\n",
        "        # Predict labels\n",
        "        y_pred = self.trained_model.predict(X)\n",
        "\n",
        "        # Compute metrics\n",
        "        self.accuracy = accuracy_score(y, y_pred)\n",
        "        self.precision = precision_score(y, y_pred, zero_division=0)\n",
        "        self.sensitivity = recall_score(y, y_pred, zero_division=0)\n",
        "\n",
        "        # Confusion matrix and specificity\n",
        "        cm = confusion_matrix(y, y_pred)\n",
        "        if cm.shape == (2, 2):\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            self.specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        else:\n",
        "            self.specificity = None\n",
        "        self.confusion_matrix_ = cm\n",
        "\n",
        "        if hasattr(self.trained_model, \"predict_proba\"):\n",
        "            y_prob = self.trained_model.predict_proba(X)[:, 1]\n",
        "            self.fpr, self.tpr, _ = roc_curve(y, y_prob)\n",
        "            self.roc_auc = auc(self.fpr, self.tpr)\n",
        "        else:\n",
        "            self.fpr = self.tpr = self.roc_auc = None\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Non altera i dati, solo per compatibilità con pipeline\n",
        "        return X\n",
        "\n",
        "    def get_results(self):\n",
        "        return {\n",
        "            \"accuracy\": self.accuracy,\n",
        "            \"precision\": self.precision,\n",
        "            \"sensitivity\": self.sensitivity,\n",
        "            \"specificity\": self.specificity,\n",
        "            \"confusion_matrix\": self.confusion_matrix_,\n",
        "            \"fpr\": self.fpr,\n",
        "            \"tpr\": self.tpr,\n",
        "            \"roc_auc\": self.roc_auc\n",
        "        }\n",
        "\n",
        "\n",
        "# Separazione delle feature e del target\n",
        "X_train = data_train.iloc[:, :-1]\n",
        "y_train = data_train.iloc[:, -1]\n",
        "\n",
        "# Ricomponiamo il DataFrame per compatibilità con i tuoi transformer personalizzati\n",
        "data_train_processed = X_train.copy()\n",
        "data_train_processed[y_train.name] = y_train  # Aggiungiamo la colonna target in fondo\n",
        "\n",
        "# Definizione della pipeline di training (senza PerformanceEvaluator)\n",
        "pipeline = Pipeline([\n",
        "    ('rename_features', FeatureRenamer(column_names=new_names_for_train_data)),\n",
        "    ('scale_data', DataScaler()),\n",
        "    ('train_decision_tree', DecisionTreeTrainer()),\n",
        "    ('cross_validate_decision_tree', DecisionTreeCrossValidator(n_splits=5, random_state=42))\n",
        "])\n",
        "\n",
        "# 1. Applica rename_features con fit_transform\n",
        "rename_step = pipeline.named_steps['rename_features']\n",
        "X_train_renamed = rename_step.fit_transform(data_train_processed)\n",
        "\n",
        "# 2. Applica scale_data con fit e transform\n",
        "scale_step = pipeline.named_steps['scale_data']\n",
        "scale_step.fit(X_train_renamed)\n",
        "X_train_scaled = scale_step.transform(X_train_renamed)\n",
        "\n",
        "# 3. Estrazione della variabile target\n",
        "y_train = X_train_scaled['health_state']\n",
        "\n",
        "\n",
        "# 4. Rimozione della variabile target dalle feature\n",
        "X_scaled_only_features = X_train_scaled.drop(columns=['health_state'])\n",
        "\n",
        "# 5. Allena il modello sui dati processati\n",
        "train_step = pipeline.named_steps['train_decision_tree']\n",
        "y_train = y_train.astype('int64')\n",
        "train_step.fit(X_scaled_only_features, y_train)\n",
        "\n",
        "# 6. Estrai il modello addestrato (assumo che l'attributo si chiami 'model')\n",
        "trained_model = train_step.model\n",
        "\n",
        "# 7. Valutazione delle performance sul training set\n",
        "evaluator = PerformanceEvaluator(trained_model=trained_model)\n",
        "evaluator.fit(X_scaled_only_features, y_train)\n",
        "results = evaluator.get_results()\n",
        "\n",
        "# 8. Stampa dei risultati\n",
        "print(\"\\nPerformance Evaluation Results:\")\n",
        "print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "print(f\"Precision: {results['precision']:.4f}\")\n",
        "print(f\"Sensitivity (Recall): {results['sensitivity']:.4f}\")\n",
        "print(f\"Specificity: {results['specificity']:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(results[\"confusion_matrix\"])\n",
        "\n",
        "if results[\"roc_auc\"] is not None:\n",
        "    plt.figure()\n",
        "    plt.plot(results[\"fpr\"], results[\"tpr\"], color='darkorange', lw=2, label=f'ROC curve (area = {results[\"roc_auc\"]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve - Training Set')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nROC curve and AUC not available (predict_proba not supported).\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPcFTLqUj7MyOaDI2emR3zL",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
